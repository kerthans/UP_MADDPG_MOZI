# Combat Simulation Environment Documentation

## 1. 环境概述

### 1.1 基本介绍
该环境是一个多智能体对抗环境(Multi-Agent Combat Environment)，用于模拟空战场景下的红蓝双方对抗。环境基于OpenAI Gym接口实现，支持多智能体强化学习训练，特别适用于MADDPG等算法。

### 1.2 核心特征
- 支持红蓝双方可配置数量的智能体
- 实现了完整的空战物理模型
- 包含丰富的奖励设计和状态空间
- 采用多线程优化以提高性能
- 支持高度可配置的参数系统

## 2. 环境架构

### 2.1 核心组件
环境由三个主要模块组成：
1. `CombatEnv`: 主环境类，负责环境的整体控制和交互
2. `StateHandler`: 状态管理器，处理智能体状态更新和观察空间
3. `CombatMechanics`: 战斗机制类，处理攻击判定和奖励计算

### 2.2 类关系图
```
CombatEnv
├── StateHandler
│   └── 状态管理与更新
└── CombatMechanics
    └── 战斗机制与奖励计算
```

## 3. 状态空间设计

### 3.1 智能体状态表示
每个智能体的状态包含5个基本维度：
- 位置 (x, y)
- 朝向 (heading)
- 速度 (speed)
- 存活状态 (alive)

### 3.2 观察空间构成
每个智能体的观察空间包含四个主要部分：
1. **自身状态** (6维)
   - 标准化的位置、速度、朝向和存活状态
   
2. **趋势特征** (5维)
   - 位置变化率
   - 速度变化率
   - 朝向变化的三角函数表示

3. **队友信息** (7维 × 最大队友数)
   - 相对位置
   - 相对速度
   - 相对朝向
   - 存活状态
   - 距离信息

4. **对手信息** (8维 × 最大对手数)
   - 相对位置
   - 相对速度
   - 存活状态
   - 相对角度
   - 攻击范围标志
   - 威胁等级
   - 距离信息

## 4. 动作空间设计

### 4.1 动作空间定义
每个智能体的动作空间是一个3维连续空间：
```python
action_space = spaces.Box(
    low=np.array([-1, -1, 0], dtype=np.float32),
    high=np.array([1, 1, 1], dtype=np.float32),
    dtype=np.float32
)
```

### 4.2 动作维度说明
1. 转向控制 [-1, 1]：控制转向速率
2. 速度控制 [-1, 1]：控制目标速度
3. 攻击决策 [0, 1]：控制是否发起攻击

## 5. 奖励系统设计

### 5.1 基础奖励组成
奖励系统包含多个组成部分：
1. 击中奖励 (hit)
2. 被击中惩罚 (be_hit)
3. 距离奖励 (distance)
4. 存活奖励 (survival)
5. 胜利/失败奖励 (win/lose)
6. 编队奖励 (formation)
7. 效率奖励 (efficiency)

### 5.2 奖励权重设计
```python
reward_weights = {
    'hit': 350.0,         # 击中奖励
    'be_hit': -120.0,     # 被击中惩罚
    'distance': -0.06,    # 距离惩罚
    'survival': 0.12,     # 存活奖励
    'win': 500.0,         # 胜利奖励
    'lose': -130.0,       # 失败惩罚
    'formation': 0.10,    # 编队奖励
    'efficiency': 0.30    # 效率奖励
}
```

### 5.3 动态奖励调整
- 实现了自适应奖励权重更新机制
- 基于历史表现动态调整奖励权重
- 采用保守的更新策略确保稳定性

## 6. 性能优化设计

### 6.1 多线程优化
- 使用ThreadPoolExecutor进行并行计算
- 状态更新和观察计算的并行处理
- 动态线程池大小配置

### 6.2 向量化计算
- 使用NumPy进行向量化运算
- 优化距离计算和状态更新
- 减少循环操作，提高计算效率

## 7. 配置系统

### 7.1 主要配置参数
```python
config = {
    'num_red': 3,              # 红方智能体数量
    'num_blue': 2,             # 蓝方智能体数量
    'max_steps': 120,          # 最大步数
    'field_size': 1000.0,      # 场地大小
    'attack_range': 100.0,     # 攻击范围
    'min_speed': 10.0,         # 最小速度
    'max_speed': 30.0,         # 最大速度
    'max_turn_rate': math.pi/6,# 最大转向速率
    'hit_probability': 0.8,    # 命中概率
    'num_threads': 8           # 线程数
}
```

### 7.2 环境边界处理
- 位置边界检查和修正
- 速度范围限制
- 转向角度标准化

## 8. 高级特性

### 8.1 威胁评估系统
实现了复杂的威胁等级计算：
- 基于距离的威胁评估
- 速度矢量分析
- 相对位置和朝向考虑

### 8.2 编队控制系统
- 基于攻击范围的理想编队半径计算
- 朝向一致性评估
- 动态编队奖励计算

### 8.3 状态缓存系统
- 使用deque实现状态历史记录
- 支持趋势特征计算
- 便于实现经验回放

## 9. 使用建议

### 9.1 参数调优建议
- 根据具体任务调整奖励权重
- 场地大小与智能体数量配比
- 攻击范围与速度参数平衡

### 9.2 性能优化建议
- 调整线程池大小
- 优化状态更新频率
- 合理设置最大步数
